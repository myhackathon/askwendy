{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "rGOx_QzXnxIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NPsTHD4EnaSp"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "openai_api_secret_name = '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'  # @param {type: \"string\"}\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=openai_api_secret_name\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_prompts = [\n",
        "    \"Tell me about yourself.\",\n",
        "    \"What are your strengths and weaknesses?\",\n",
        "    \"Describe a time you faced a challenge and how you overcame it.\",\n",
        "    \"Why are you interested in this position?\",\n",
        "    \"What are your salary expectations?\",\n",
        "    \"Introduce yourself and provide a brief overview of your background and experience.\",\n",
        "    \"Can you describe a time when you successfully led a team or project? What was the outcome?\",\n",
        "    \"Tell me about a challenging problem you encountered at work and how you solved it.\",\n",
        "    \"Provide an example of effective collaboration within a team. What was your role?\",\n",
        "    \"Describe a situation where you had to communicate complex information to a non-technical audience.\",\n",
        "    \"How have you handled significant changes or unexpected challenges in the workplace?\",\n",
        "    \"Give an example of a time when you successfully met a tight deadline. How did you prioritise your tasks?\",\n",
        "    \"Describe a situation where you took initiative to improve a process or procedure at work.\",\n",
        "    \"Can you share an experience of resolving a conflict with a colleague or team member?\",\n",
        "    \"Tell me about a difficult decision you had to make at work and how you approached it.\",\n",
        "    \"Provide an example of demonstrating excellent customer focus or satisfaction.\",\n",
        "]\n",
        "\n",
        "def evaluate(question_id):\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": '%s -- I want you to act as an interviewer that provides useful and constructive feedback for the following interview question and response.' % question_id}]\n",
        "        )\n",
        "\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "user_answer = \"I am a cat who likes to do nothing all day\"\n",
        "\n",
        "print(evaluate(interview_prompts[0]))"
      ],
      "metadata": {
        "id": "r1TEpvHepIO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e1a64e2-d9a7-4aed-c93f-88bf909a5f7d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interviewer: Can you tell me about yourself?\n",
            "\n",
            "Response: Sure! I have a background in marketing and have worked in various industries such as healthcare, technology, and retail. I am highly skilled in digital marketing strategies and have a strong track record of successfully executing campaigns that drive brand awareness and lead generation. In my previous role, I was responsible for developing and implementing a comprehensive social media strategy that resulted in a 30% increase in online engagement. I am passionate about staying current on industry trends and leveraging data-driven insights to inform my decision-making process.\n",
            "\n",
            "Interviewer feedback: Your response is well-structured and provides a clear overview of your experience and skills. It's great that you highlighted specific accomplishments from your previous role to showcase your successful track record. One suggestion for improvement would be to briefly mention how your background and skills align with the position you are applying for, as this can help the interviewer see how you are a good fit for the role. Overall, you did a good job of showcasing your expertise and enthusiasm for marketing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(question_id):\n",
        "  interview_question = question_id\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": '%s -- Please answer as concisely as you can, avoiding any extra conversation or text' % interview_question}\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  return completion.choices[0].message.content\n",
        "\n",
        "\n",
        "print(evaluate(interview_prompts[0]))\n",
        "\n",
        "def process_interview(question_id, job_description=None):\n",
        "  # user_response = listen_user()\n",
        "  # if user_response is None:\n",
        "  #   return \"Sorry, I couldn't understand you. Please try again.\"\n",
        "\n",
        "  # feedback = process_input(question_id, user_response, job_description)\n",
        "  # speak(feedback)\n",
        "  feedback =\"Not online yet\"\n",
        "  return feedback\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=process_interview,\n",
        "    inputs=[\n",
        "        gr.Dropdown(label=\"Select Interview Question\", choices=interview_prompts),\n",
        "        gr.Textbox(label=\"Job Description (Optional)\"),\n",
        "        gr.Textbox(label = \"Your response\"),\n",
        "        gr.Button(value=\"Get Feedback\", elem_id=\"get_feedback_button\"),  # Button to trigger processing\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Ask Wendy Young Women's Trust Chatbot\",\n",
        "    description=\"\"\"Practice your interview skills and get spoken feedback on your answers.\n",
        "  1. Choose an interview question.\n",
        "  2. Optionally, include the job description.\n",
        "  3. Click the \"Get Feedback\" button.\n",
        "\n",
        "The AI will analyze your spoken response and provide spoken feedback on its strengths and areas for improvement based on the job description.\"\"\",\n",
        ")\n",
        "\n",
        "# Disable text input box by default (optional)\n",
        "#text_input = iface.widgets[1]  # Get the textbox element (second input)\n",
        "#text_input.visible = False  # Hide the textbox initially\n",
        "\n",
        "# Function to handle button click and trigger processing based on microphone input\n",
        "def get_feedback_button_click(btn):\n",
        "  feedback = process_interview(iface.inputs[0].value)  # Get question ID from dropdown\n",
        "  iface.outputs.text = feedback  # Update text output with feedback\n",
        "\n",
        "# Connect the button click event to the function\n",
        "#button = iface.widgets[3]  # Get the button element (fourth input)\n",
        "#button.click_event(get_feedback_button_click)\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "GUl05pAencmF",
        "outputId": "eed36985-e1c5-495b-f957-19352a9388a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************g9ox. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-88945d755c89>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterview_prompts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_interview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_description\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-88945d755c89>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(question_id)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0minterview_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 579\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         )\n\u001b[0;32m-> 1240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 921\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    922\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************g9ox. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ro_5ttR7U-PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZqDXV93U2Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJf5GCg4Tj2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HN5Pe34vP7aW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}